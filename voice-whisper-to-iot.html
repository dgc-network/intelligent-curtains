<!DOCTYPE html>
<html lang="zh-TW">
<head>
  <meta charset="UTF-8">
  <title>Voice â†’ IoT Control</title>
  <style>
    body { font-family: sans-serif; padding: 2em; }
    button { padding: 1em 2em; font-size: 1.1rem; }
    #status { margin-top: 1em; font-weight: bold; }
    #result { margin-top: 1em; padding: 1em; border: 1px solid #ccc; }
  </style>
</head>
<body>
  <h1>ğŸ™ï¸ èªéŸ³æ§åˆ¶ IoT</h1>
  <button id="startBtn">â–¶ï¸ é–‹å§‹éŒ„éŸ³</button>
  <div id="status">ç‹€æ…‹ï¼šç­‰å¾…ä¸­â€¦â€¦</div>
  <div id="result"><strong>è¾¨è­˜/æŒ‡ä»¤ï¼š</strong><span id="text"></span></div>

  <script>
  (async()=>{

    const OPENAI_API_KEY = 'YOUR_OPENAI_API_KEY';
    const WEBHOOK_URL     = 'https://aihome.tw/wp-json/iot/v1/command';

    const startBtn = document.getElementById('startBtn');
    const statusEl = document.getElementById('status');
    const textEl   = document.getElementById('text');

    // 1ï¸âƒ£ å°è¯•æµè§ˆå™¨åŸç”Ÿè¯†åˆ«
    let recognition, useNative = true;
    try {
      const R = window.SpeechRecognition||window.webkitSpeechRecognition;
      recognition = new R();
      recognition.lang = 'zh-TW';
      recognition.interimResults = false;
      recognition.continuous = false;

      recognition.onstart = ()=> statusEl.textContent = 'ç‹€æ…‹ï¼šğŸ§ Listening...';
      recognition.onerror = e=> statusEl.textContent = `ç‹€æ…‹ï¼šâŒ ${e.error}`;
      recognition.onresult = e=>{
        const txt = e.results[0][0].transcript;
        textEl.textContent = txt;
        statusEl.textContent = 'ç‹€æ…‹ï¼šâœ… Received';
        handleVoice(txt);
      };
    } catch(_){
      useNative = false;
      startBtn.textContent = 'â–¶ï¸ éŒ„éŸ³ï¼ˆWhisperï¼‰';
    }

    startBtn.onclick = ()=> {
      if(useNative){
        recognition.start();
      } else {
        recordViaWhisper();
      }
    };

    // 2ï¸âƒ£ Whisper å½•éŸ³+ä¸Šä¼ 
    async function recordViaWhisper(){
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      const mr = new MediaRecorder(stream), chunks=[];
      mr.ondataavailable = e=> chunks.push(e.data);
      mr.onstop = async ()=>{
        statusEl.textContent = 'ç‹€æ…‹ï¼šâ³ è¾¨è­˜ä¸­â€¦';
        const blob = new Blob(chunks,{type:'audio/webm'});
        const fd = new FormData();
        fd.append('file', blob, 'audio.webm');
        fd.append('model','whisper-1');
        const res = await fetch('https://api.openai.com/v1/audio/transcriptions',{
          method:'POST',
          headers:{ 'Authorization':`Bearer ${OPENAI_API_KEY}` },
          body: fd
        });
        const j = await res.json();
        const txt = j.text||'';
        textEl.textContent = txt;
        statusEl.textContent = 'ç‹€æ…‹ï¼šâœ… Whisper å®Œæˆ';
        handleVoice(txt);
      };
      mr.start();
      startBtn.textContent = 'â¹ åœæ­¢éŒ„éŸ³';
      mr.onstop = mr.ondataavailable;
      setTimeout(()=> mr.stop(), 5000);  // æœ€å¤šéŒ„ 5s
    }

    // 3ï¸âƒ£ ç”¨ ChatGPT Function Calling æŠ½å– intent
    async function handleVoice(spoken){
      statusEl.textContent = 'ç‹€æ…‹ï¼šâŒ› è§£ææŒ‡ä»¤â€¦';
      const resp = await fetch('https://api.openai.com/v1/chat/completions',{
        method:'POST',
        headers:{
          'Content-Type':'application/json',
          'Authorization':`Bearer ${OPENAI_API_KEY}`
        },
        body: JSON.stringify({
          model: 'gpt-4-0613',
          messages:[
            { role:'system',
              content:'ä½ æ˜¯æ™ºæ…§å®¶åº­åŠ©ç†ï¼Œå›å‚³ function_call JSON {action,device,location}ï¼Œå‹•ä½œ enum: é–‹å•Ÿ/é—œé–‰ï¼Œè£ç½® enum: ç‡ˆ/å†·æ°£/çª—ç°¾/é›»è¦–ã€‚' },
            { role:'user', content: spoken }
          ],
          functions:[{
            name:'control_device',
            description:'æ§åˆ¶è£ç½®',
            parameters:{
              type:'object',
              properties:{
                action:{ type:'string', enum:['é–‹å•Ÿ','é—œé–‰'] },
                device:{ type:'string', enum:['ç‡ˆ','å†·æ°£','çª—ç°¾','é›»è¦–'] },
                location:{ type:'string' }
              },
              required:['action','device','location']
            }
          }],
          function_call:'auto'
        })
      });
      const js = await resp.json();
      const args = JSON.parse(js.choices[0].message.function_call.arguments);
      textEl.textContent = `${args.action} ${args.device} @${args.location}`;
      statusEl.textContent = 'ç‹€æ…‹ï¼šğŸ“¡ å‚³é€åˆ° IoTâ€¦';

      // 4ï¸âƒ£ å‚³çµ¦ WordPress Webhook
      const out = await fetch(WEBHOOK_URL, {
        method:'POST',
        headers:{ 'Content-Type':'application/json' },
        body: JSON.stringify(args)
      });
      if(out.ok){
        statusEl.textContent = 'ç‹€æ…‹ï¼šâœ… æŒ‡ä»¤å·²é€å‡º';
      } else {
        statusEl.textContent = 'ç‹€æ…‹ï¼šâŒ Webhook å¤±æ•—';
      }
    }

  })();
  </script>
</body>
</html>
